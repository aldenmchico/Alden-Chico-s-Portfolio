## Character Impact Project ReadMe

The character impact project was a personal project of mine where I set out to record the amount of time each character spent on screen for the hit TV show The Office. I was able to achieve a nearly perfect facial recognition model that predicted still images of each character from the show with 99.75% accuracy on 99.75% F1. The final image-video processing pipeline that I deployed used the Multitask Convolutional Neural Network architecture for facial detection, FaceNet for image vector embedding, and a Support Vector Machine for facial recognition. Using this pipeline for every frame of the video allowed me to capture the screen time for each individual character in the show. This image-video processing pipeline can be extended to any video medium that stars unmasked human characters.

To start my project off, I performed data wrangling over the Internet Movie Database (IMDb) publicly available datasets. IMDb provides publicly available tab-separated value files that contain basic information about all the movies and television series available on their website. The tables are organized using primary keys that associate information from one table to another, so by merging these tables together using Pandas DataFrames, I extracted all the relevant information for the first season of The Office. Cast and character information for each individual episode wasn't included from these TSV files, so I used Python's request library and BeautifulSoup to extract this information from the IMDb website.

After I extracted all the information that I could from IMDb's website, I explored the IMDb data by collecting information from the actors and actressesses involved in the show. This information included demographic information such as age, ethnicity, and gender for each character from The Office. I compiled this information into a single visual graphic using Matplotlib and Seaborn. What I found was that a majority of the cast members from the show at the time of shooting were caucasian white males in their early 30s. This information was useful to know prior to facial recognition to see if the similarity in character demographic may cause confusion in predicting characters to their faces.

After analyzing character demographic information for character's in The Office, I then moved on to facial detection. At the start of my project, I explored facial detection using OpenCV, an open source library with built in facial detection classifiers. Seeing that every 22 minute episode contains around 40000 frames, I needed to choose a fast classification model. I analyzed runtime performance for the Haar Cascade Classifier vs. the Local Binary Pattern Histogram (LBPH) classifier and found that the average runtime for LBPH on my Macbook Pro 2015 personal computer was 19.73 ms faster per image than Haar classification. For this reason, I set out to use LBPH for the rest of my project.

LBPH is both a facial detection and facial recognition algorithm. The issue that I found in using LBPH, though, was that facial recognition using LBPH dropped off considerably after expanding the character set from 4 to 22 characters. I needed to administer a more robust facial recognition algorithm since LBPH facial recognition was only able to achieve an F1 score of 70.54%. The solution to this problem was FaceNet. FaceNet is a facial embedding algorithm developed by researchers at Google that takes face images as input and outputs a 128 dimensional vector as output. FaceNet uses what the researchers call a triplet-loss function to embed vectors of people with the same identity geometrically closer to one another than vectors of different individuals. Minimizing the triplet loss function in training the FaceNet image convolutional neural network (CNN) embedder across thousands of individual identities yields a CNN that successfully embeds unique vectors for individual characters of The Office. Detecting faces using LBPH, embedding the face images with FaceNet, and training an SVM on these vectors yielded an F1 performance of character recognition of 97.11% for new character images. All of the errors from using this modeling process came from misdetection of a character's face from the frame.

To improve facial detection, I replaced LBPH facial detection with another CNN architecture known as Multitask Convolutional Neural Network (MTCNN). MTCNN takes an image as input and draws a bounding box and facial feature landmarks where individual eyes, noses, and mouths are located. The MTCNN model weights that I downloaded from GitHub user Iv√°n de Paz Centeno was trained on the Labeled Faces in the Wild (LFW) dataset. Using the MTCNN on my own project only misdetected a single face from the 500+ image set that I predicted on.

So, using images that I found online for every character on the show, I augmented the images to train my SVM on 500 images per character. Augmenting images means using editing functions like zoom, crop, and shear to create more images that are useful for training a predictive model. Using these 500 images per character, I detected faces from these images using MTCNN, embedded the faces using FaceNet, and trained an SVM using the embedded face vectors. Then, when predicting on episodes from the first season of The Office, I took every individual frame, detected faces from the frame using MTCNN, embedded the faces using FaceNet, and predicted a label to the vector using the trained SVM. I then stored the face images from each character to the character's respective project directory and repeated this process for every frame of the first season of The Office.

After performing this entire process, I had directories in my project directory for each character in the show and their recognized faces. I counted the number of face images in each character's directory and divided by the frame rate of the show (24 FPS) to get the number of seconds each character spent on screen. I then took this information, edited the IMDb website's character table information for each episode of the show to include this information, and stored the edited HTML into separate text files.

Overall, this project taught me a lot about facial recognition and its deployment on real world data. Accurately measuring character screen time can help writers and executive producers leverage better decisions for their movies and television shows and I look forward to the future where data analysts can work with these key decision makers to improve the ever growing entertainment industry.
